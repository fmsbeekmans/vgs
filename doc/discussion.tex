\section{Discussion}
In this chapter the trade-offs inherent in the design of the system are discussed. Based on the results described in the section above a verdict will provided deciding whether WantDS BV should use a distributed system as the one designed or not.

\subsection{Topology trade-offs}
As discussed on the section 3, two different topologies were analyzed. The ring topology was initially chosen because of the robustness of that kind of networks [2]. Another merit for this topology is the low message exchange in the whole system, making it easily scalable. Additional components could be added in the hypothetical situation that the system needs to conduct a higher workload not covered by current capabilities. However, as analyzed in section 3.1 the topology is rather sensitive to cascading failures. This sensibility is inherent to the design of the topology, even in a completely balanced system where every cluster has a maximum load of 50\% over the total capacity, the failure of one RM will cause the overload of the new selected cluster. Nevertheless, since the implementation of the first approach was not completed there is no empiric confirmation regarding this issue. The likely possibility of cascading failures and, the need of a complex protocol to coordinate how components join the system on initialization and after a failure were enough reasons to discard this design. On the other hand, as discussed earlier, the fully connected topology is easy to initialize, the Repository solution, presented in section 4, facilitates the discovery and starting process as components only need to know the URLs of the rest of the system. Thus, there is no need of a protocol to rearrange the topology when components comes back to life after a failure, they will simply contact again the entities on the repository and their status will be automatically updated. However, in massive systems with thousands of clusters this process may become slower since they have to contact all the entities. The random selection of a GS for monitoring and back-up mitigates the impact of overloading a specific component reducing the risk of domino failure. A negative consequence of the fault recovery scheme is that if an RM fails after all the jobs have been submitted, it will remain idle for the rest of the execution even if the other clusters are full. However, in realistic scenarios it is sensible to assume that the arrival patterns will not consist on only one burst of job requests but more continuous over the time.

\subsection{Scalability}
As advanced on the section 3, the scalability of the system is $O(n^2)$, nonetheless, as the sizes of the ping messages and the job requests are not very high, the system is able to work properly under the required conditions. It is expected that if there is a change on the workload characteristics or the number of components scales several orders of magnitude the system will not be able to provide the service it is intended to. However, as explained in the experiments section the maximum number of RM and GS the system was able to support at the same time was: XX and YY respectively with ZZ simultaneous users. Thus, there is still margin in case that WantDS needs to upgrade its system.

\subsection{Load balance}
GSs load balance the system in two different ways: first, when a job is offloaded from an RM, the receptor GS will select the new RM using an inverted weighed random selection with the load of the clusters. This means that GSs will keep the system balanced while dealing with offloaded jobs. The second way is when an RM crashes, the GS in charge of its recovery will also select the new RMs using the aforementioned selector, thus, the system is also balanced while dealing with failures. There are other possible load balancing policies that were not included on the system for the sake of simplicity, such as an active load balance initiated by GSs. In that scenario, GSs will periodically take action and reallocate jobs from heavy loaded clusters to lightly ones. This new possibility, even if not implemented, is thought to be more effective in terms of load balance. However, new issues would arise with this policy, for instance establishing the threshold for the reallocation to start, whether clusters should suspend their activity while the reallocating process takes place or, which GS initiates the load balance.

\section{Conclusion}
In this report, the design of the Virtual Grid System (VGS) is presented. First, the two considered topologies: the ring topology and the fully connected topology are analyzed and compared regarding fault tolerance, load balance and scalability. Due to the sensitivity to cascading failures and the need of a complex protocol to coordinate initialization and how components reconnect after a failure, the ring topology was discarded. Next, the main implementation decisions are explained. After that, the conducted experiments are described. The focus of the experiments is on the fairness of the system while dealing with multiple users at the same time, fault tolerance, scalability and, verification of the correct functionality of the offloading. Finally, the trade-offs and drawbacks of the design are discussed.
\\\\
After performing the experiments, we can conclude that the system is resilient to two simultaneous failures. While the number of messages in the system is high, the system is able to provide the functionality it is intended to, with a considerable margin before scalability starts becoming an issue. When dealing with multiple users at the same time the system treats users evenly, offering a similar average completion execution time per job to every user. Lastly, the load of the system is balanced by the GSs when a job is offloaded or needs to be reallocated in a new cluster due to a failure. The conclusion of this report is that WantDS should use a distributed system as defined in this report, since it meets all of their requirements on fault tolerance, scalability and load balance.